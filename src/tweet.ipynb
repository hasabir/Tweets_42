{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = pd.DataFrame()\n",
    "negative = pd.DataFrame()\n",
    "neutral = pd.DataFrame()\n",
    "\n",
    "positive[\"positive\"] = pd.read_csv('../data/processedPositive.csv', header=None ).T.squeeze()\n",
    "negative[\"negative\"] = pd.read_csv('../data/processedNegative.csv', header=None).T.squeeze()\n",
    "neutral[\"neutral\"] = pd.read_csv('../data/processedNeutral.csv', header=None).T.squeeze()\n",
    "\n",
    "\n",
    "\n",
    "merged = pd.merge(positive, negative, left_index=True, right_index=True)\n",
    "data_frame = pd.merge(merged, neutral, left_index=True, right_index=True)\n",
    "\n",
    "# data_frame = data_frame.sample(frac=0.2, random_state=1)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An inspiration in all aspects: Fashion'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['positive'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "positif = pd.read_csv('../data/processedPositive.csv', header=None).T.squeeze()\n",
    "negatif = pd.read_csv('../data/processedNegative.csv', header=None).T.squeeze()\n",
    "netral = pd.read_csv('../data/processedNeutral.csv', header=None).T.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               An inspiration in all aspects: Fashion\n",
       "1                                              fitness\n",
       "2      beauty and personality. :)KISSES TheFashionIcon\n",
       "3    Apka Apna Awam Ka Channel Frankline Tv Aam Adm...\n",
       "4    Beautiful album from  the greatest unsung guit...\n",
       "5    Good luck to Rich riding for great project in ...\n",
       "6              Omg he... kissed... him crying with joy\n",
       "7       happy anniv ming and papi!!!!! love love happy\n",
       "8                                         thanks happy\n",
       "9                                         C'mon Tweeps\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positif[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mtokenize\u001b[38;5;241m.\u001b[39mRegexpTokenizer(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m positif \u001b[38;5;129;01min\u001b[39;00m data_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 6\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositif\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# print(tokens)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \n\u001b[1;32m      9\u001b[0m     \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# positif_tokens[:10]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/nltk/tokenize/regexp.py:133\u001b[0m, in \u001b[0;36mRegexpTokenizer.tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_regexp\u001b[38;5;241m.\u001b[39msplit(text)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# If our regexp matches tokens, use re.findall:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_regexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object, got 'float'"
     ]
    }
   ],
   "source": [
    "positif_tokens = []\n",
    "negatif_tokens = []\n",
    "netral_tokens = []\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "for positif in data_frame['positive']:\n",
    "    tokens = tokenizer.tokenize(positif)\n",
    "    # print(tokens)\n",
    "    \n",
    "    \n",
    "# positif_tokens[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform tweets to vectors (Vectorisation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'positif' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m positif_bag_of_words \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpositif\u001b[49m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m review\u001b[38;5;241m.\u001b[39msplit():\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m positif_bag_of_words:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'positif' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "positif_bag_of_words = {}\n",
    "for review in positif:\n",
    "    for word in review.split():\n",
    "        if word in positif_bag_of_words:\n",
    "            positif_bag_of_words[word] += 1\n",
    "        else:\n",
    "            positif_bag_of_words[word] = 1\n",
    "\n",
    "negative_bag_of_words = {}\n",
    "for review in negatif:\n",
    "    for word in review.split():\n",
    "        if word in negative_bag_of_words:\n",
    "            negative_bag_of_words[word] += 1\n",
    "        else:\n",
    "            negative_bag_of_words[word] = 1\n",
    "\n",
    "netral_bag_of_words = {}\n",
    "for review in netral:\n",
    "    for word in review.split():\n",
    "        if word in netral_bag_of_words:\n",
    "            netral_bag_of_words[word] += 1\n",
    "        else:\n",
    "            netral_bag_of_words[word] = 1\n",
    "\n",
    "positif_bag_of_words = pd.DataFrame.from_dict(positif_bag_of_words, orient='index', columns=['Positif']).T\n",
    "negative_bag_of_words = pd.DataFrame.from_dict(negative_bag_of_words, orient='index', columns=['Negatif']).T\n",
    "netral_bag_of_words = pd.DataFrame.from_dict(netral_bag_of_words, orient='index', columns=['Netral']).T\n",
    "\n",
    "\n",
    "bag_of_words = pd.concat([positif_bag_of_words, negative_bag_of_words, netral_bag_of_words], axis=0)\n",
    "bag_of_words = bag_of_words.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF (Term Frequency-Inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
