{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def train_with_gridsearch(train_df, test_df, vectorizer, model, param_grid, description):\n",
    "    with open('../data/raw_splits/train.csv', 'r') as f:\n",
    "        raw_train_df = pd.read_csv(f)\n",
    "    \n",
    "\n",
    "    raw_test_df = pd.read_csv('../data/raw_splits/test.csv')\n",
    "\n",
    "    y_train = raw_train_df['label'].to_numpy().astype(int)\n",
    "    y_test = raw_test_df['label'].to_numpy().astype(int)\n",
    "\n",
    "    X_train_vector = csr_matrix(train_df.values)\n",
    "    X_test_vector = csr_matrix(test_df.values)\n",
    "\n",
    "    print(\"X_train_vector shape:\", X_train_vector.shape)\n",
    "    print(\"X_test_vector shape:\", X_test_vector.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "    \n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train_vector, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    best_model.fit(X_train_vector, y_train)\n",
    "    y_pred = best_model.predict(X_test_vector)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Best Parameters for \\033[95m{description}\\033[00m: \\033[93m{grid_search.best_params_}\\033[00m with accuracy: \\033[92m{accuracy}\\033[00m\")\n",
    "    return accuracy, grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vector shape: (2837, 4300)\n",
      "X_test_vector shape: (703, 4300)\n",
      "y_train shape: (2846,)\n",
      "y_test shape: (712,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2837, 2846]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m param_grids\u001b[38;5;241m.\u001b[39mget(model_name, {})  \u001b[38;5;66;03m# Get hyperparameter grid for the model\u001b[39;00m\n\u001b[1;32m     45\u001b[0m description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m + \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 47\u001b[0m accuracy, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_with_gridsearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorizers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvectorizer_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     52\u001b[0m     results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_name,\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessing_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_file,\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy,\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Params\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(best_params)\n\u001b[1;32m     57\u001b[0m     }])\n",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m, in \u001b[0;36mtrain_with_gridsearch\u001b[0;34m(train_df, test_df, vectorizer, model, param_grid, description)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_test shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     24\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     29\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(X_train_vector, y_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.10/site-packages/sklearn/model_selection/_search.py:927\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    924\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\n\u001b[1;32m    925\u001b[0m scorers, refit_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_scorers()\n\u001b[0;32m--> 927\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_method_params(X, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m    930\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_routed_params_for_fit(params)\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.10/site-packages/sklearn/utils/validation.py:532\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \n\u001b[1;32m    504\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    531\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 532\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.10/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2837, 2846]"
     ]
    }
   ],
   "source": [
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": [0.1, 1, 10],  # Regularization strength\n",
    "        \"max_iter\": [100, 200, 500]\n",
    "    },\n",
    "    \"MultinomialNB\": {\n",
    "        \"alpha\": [0.1, 0.5, 1.0]  # Smoothing parameter\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"kernel\": [\"linear\", \"rbf\"]  # Different kernel functions\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "vectorizers = {\n",
    "    \"TF-IDF\": TfidfVectorizer(),\n",
    "    \"Bow\": CountVectorizer(binary=False),\n",
    "    \"BinaryVectorizer\": CountVectorizer(binary=True),\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"SVC\": SVC(),\n",
    "}\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=[\"model\", \"processing_method\", \"Accuracy\", \"Best Params\"])\n",
    "\n",
    "train_dir = \"../data/prepocessed_training_data\"\n",
    "test_dir = \"../data/prepocessed_testing_data\"\n",
    "\n",
    "train_files = sorted(os.listdir(train_dir))\n",
    "test_files = sorted(os.listdir(test_dir))\n",
    "\n",
    "for train_file, test_file in zip(train_files, test_files):\n",
    "    vectorizer_name = train_file.split(\"_\")[-1].replace(\".csv\", \"\")\n",
    "\n",
    "    train_df = pd.read_csv(os.path.join(train_dir, train_file))\n",
    "    test_df = pd.read_csv(os.path.join(test_dir, test_file))\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        param_grid = param_grids.get(model_name, {})  # Get hyperparameter grid for the model\n",
    "        description = f\"{train_file} + {model_name}\"\n",
    "\n",
    "        accuracy, best_params = train_with_gridsearch(\n",
    "            train_df, test_df, vectorizers[vectorizer_name], model, param_grid, description\n",
    "        )\n",
    "\n",
    "        if results.empty:\n",
    "            results = pd.DataFrame([{\n",
    "                \"model\": model_name,\n",
    "                \"processing_method\": train_file,\n",
    "                \"Accuracy\": accuracy,\n",
    "                \"Best Params\": str(best_params)\n",
    "            }])\n",
    "        else:\n",
    "            results = pd.concat([results, pd.DataFrame([{\n",
    "                \"model\": model_name,\n",
    "                \"processing_method\": train_file,\n",
    "                \"Accuracy\": accuracy,\n",
    "                \"Best Params\": str(best_params)\n",
    "            }])], ignore_index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
