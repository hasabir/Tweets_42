{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>would great trick happy</td>\n",
       "      <td>far worst day  since january th unhappy crying...</td>\n",
       "      <td>decide new legislative party leader future cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nailed it brought tears eyes</td>\n",
       "      <td>played fm long time really should unhappy</td>\n",
       "      <td>bjp rushes shake uppercaste tag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mini campervan happy</td>\n",
       "      <td>tell unhappy</td>\n",
       "      <td>govt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thanks recent follow much appreciated happy want</td>\n",
       "      <td>nani lies unconscious</td>\n",
       "      <td>antiterror operation lucknows outskirts ends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>definitely looking  gave try anyway happy</td>\n",
       "      <td>blast okay love you</td>\n",
       "      <td>quaint digs budget or even less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>happy</td>\n",
       "      <td>year haha unhappy</td>\n",
       "      <td>offered help</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            positive  \\\n",
       "0                            would great trick happy   \n",
       "1                       nailed it brought tears eyes   \n",
       "2                               mini campervan happy   \n",
       "3  thanks recent follow much appreciated happy want    \n",
       "4          definitely looking  gave try anyway happy   \n",
       "5                                              happy   \n",
       "\n",
       "                                            negative  \\\n",
       "0  far worst day  since january th unhappy crying...   \n",
       "1          played fm long time really should unhappy   \n",
       "2                                       tell unhappy   \n",
       "3                              nani lies unconscious   \n",
       "4                                blast okay love you   \n",
       "5                                  year haha unhappy   \n",
       "\n",
       "                                             neutral  \n",
       "0  decide new legislative party leader future cou...  \n",
       "1                    bjp rushes shake uppercaste tag  \n",
       "2                                               govt  \n",
       "3       antiterror operation lucknows outskirts ends  \n",
       "4                    quaint digs budget or even less  \n",
       "5                                       offered help  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "\n",
    "from lib.data_preparation import DataPreparation\n",
    "\n",
    "\n",
    "data_set = DataPreparation.remove_stopwords(DataPreparation.load_data())\n",
    "data_set = DataPreparation.clean_data(data_set)\n",
    "\n",
    "\n",
    "data_set = data_set.sample(frac=0.005).reset_index(drop=True)\n",
    "data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "tokenized_data_frame = pd.DataFrame()\n",
    "for column in data_set.columns:\n",
    "    tokenized_data_frame[column] = data_set[column].astype(str).apply(tokenizer.tokenize)\n",
    "\n",
    "print(tokenized_data_frame.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[would, great, trick, happy]</td>\n",
       "      <td>[far, worst, day, since, january, th, unhappy,...</td>\n",
       "      <td>[decide, new, legislative, party, leader, futu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[nailed, it, brought, tears, eyes]</td>\n",
       "      <td>[played, fm, long, time, really, should, unhappy]</td>\n",
       "      <td>[bjp, rushes, shake, uppercaste, tag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[mini, campervan, happy]</td>\n",
       "      <td>[tell, unhappy]</td>\n",
       "      <td>[govt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[thanks, recent, follow, much, appreciated, ha...</td>\n",
       "      <td>[nani, lies, unconscious]</td>\n",
       "      <td>[antiterror, operation, lucknows, outskirts, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[definitely, looking, gave, try, anyway, happy]</td>\n",
       "      <td>[blast, okay, love, you]</td>\n",
       "      <td>[quaint, digs, budget, or, even, less]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[happy]</td>\n",
       "      <td>[year, haha, unhappy]</td>\n",
       "      <td>[offered, help]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            positive  \\\n",
       "0                       [would, great, trick, happy]   \n",
       "1                 [nailed, it, brought, tears, eyes]   \n",
       "2                           [mini, campervan, happy]   \n",
       "3  [thanks, recent, follow, much, appreciated, ha...   \n",
       "4    [definitely, looking, gave, try, anyway, happy]   \n",
       "5                                            [happy]   \n",
       "\n",
       "                                            negative  \\\n",
       "0  [far, worst, day, since, january, th, unhappy,...   \n",
       "1  [played, fm, long, time, really, should, unhappy]   \n",
       "2                                    [tell, unhappy]   \n",
       "3                          [nani, lies, unconscious]   \n",
       "4                           [blast, okay, love, you]   \n",
       "5                              [year, haha, unhappy]   \n",
       "\n",
       "                                             neutral  \n",
       "0  [decide, new, legislative, party, leader, futu...  \n",
       "1              [bjp, rushes, shake, uppercaste, tag]  \n",
       "2                                             [govt]  \n",
       "3  [antiterror, operation, lucknows, outskirts, e...  \n",
       "4             [quaint, digs, budget, or, even, less]  \n",
       "5                                    [offered, help]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Stemmming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_data = pd.DataFrame()\n",
    "\n",
    "for column in tokenized_data_frame.columns:\n",
    "    stemmed_data[column] = tokenized_data_frame[column].apply(lambda row: [stemmer.stem(word) for word in row])\n",
    "print(stemmed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[would, great, trick, happy]</td>\n",
       "      <td>[far, bad, day,  , since, january, th, unhappy...</td>\n",
       "      <td>[decide, new, legislative, party, leader, futu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[nail, it, bring, tear, eye]</td>\n",
       "      <td>[play, fm, long, time, really, should, unhappy]</td>\n",
       "      <td>[bjp, rush, shake, uppercaste, tag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[mini, campervan, happy]</td>\n",
       "      <td>[tell, unhappy]</td>\n",
       "      <td>[govt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[thank, recent, follow, much, appreciated, hap...</td>\n",
       "      <td>[nani, lie, unconscious]</td>\n",
       "      <td>[antiterror, operation, lucknow, outskirt, end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[definitely, looking,  , gave, try, anyway, ha...</td>\n",
       "      <td>[blast, okay, love, you]</td>\n",
       "      <td>[ , quaint, dig, budget, or, even, less]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[happy]</td>\n",
       "      <td>[year, haha, unhappy]</td>\n",
       "      <td>[offer, help]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            positive  \\\n",
       "0                       [would, great, trick, happy]   \n",
       "1                       [nail, it, bring, tear, eye]   \n",
       "2                           [mini, campervan, happy]   \n",
       "3  [thank, recent, follow, much, appreciated, hap...   \n",
       "4  [definitely, looking,  , gave, try, anyway, ha...   \n",
       "5                                            [happy]   \n",
       "\n",
       "                                            negative  \\\n",
       "0  [far, bad, day,  , since, january, th, unhappy...   \n",
       "1    [play, fm, long, time, really, should, unhappy]   \n",
       "2                                    [tell, unhappy]   \n",
       "3                           [nani, lie, unconscious]   \n",
       "4                           [blast, okay, love, you]   \n",
       "5                              [year, haha, unhappy]   \n",
       "\n",
       "                                             neutral  \n",
       "0  [decide, new, legislative, party, leader, futu...  \n",
       "1                [bjp, rush, shake, uppercaste, tag]  \n",
       "2                                             [govt]  \n",
       "3    [antiterror, operation, lucknow, outskirt, end]  \n",
       "4           [ , quaint, dig, budget, or, even, less]  \n",
       "5                                      [offer, help]  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "lemmatized_words = pd.DataFrame()\n",
    "for column in data_set.columns:\n",
    "    lemmatized_words[column] = data_set[column].astype(str).apply(\n",
    "        lambda row: [token.lemma_ for token in nlp(row)]\n",
    "    )\n",
    "    \n",
    "lemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "### Stemming + misspellings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### misspelling correction with jaccard_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "from rapidfuzz import process\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import words\n",
    "import nltk\n",
    "\n",
    "nltk.download('words')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "corrected_stemmed_data = pd.DataFrame()\n",
    "\n",
    "def get_closest_word(word, threshold=80):\n",
    "    match = process.extractOne(word, words.words(), score_cutoff=threshold)\n",
    "    if match :\n",
    "        return match[0]\n",
    "    return word\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[would, great, trick, happi]</td>\n",
       "      <td>[far, worst, day, sinc, a, th, unhappi, cri, cri]</td>\n",
       "      <td>[decid, new, legisl, parti, leader, futur, cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[a, it, brought, a, angeley]</td>\n",
       "      <td>[splay, chaffman, long, time, realli, should, ...</td>\n",
       "      <td>[b, brush, shake, as, tag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[adminicl, am, happi]</td>\n",
       "      <td>[tell, unhappi]</td>\n",
       "      <td>[g]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[thank, recent, follow, much, appreci, happi, ...</td>\n",
       "      <td>[a, alli, unconsci]</td>\n",
       "      <td>[an, oper, know, outskirt, amend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[definit, look, gave, tri, anyway, happi]</td>\n",
       "      <td>[blast, a, love, you]</td>\n",
       "      <td>[quaint, dig, budget, or, even, less]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[happi]</td>\n",
       "      <td>[year, a, unhappi]</td>\n",
       "      <td>[goffer, help]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            positive  \\\n",
       "0                       [would, great, trick, happi]   \n",
       "1                       [a, it, brought, a, angeley]   \n",
       "2                              [adminicl, am, happi]   \n",
       "3  [thank, recent, follow, much, appreci, happi, ...   \n",
       "4          [definit, look, gave, tri, anyway, happi]   \n",
       "5                                            [happi]   \n",
       "\n",
       "                                            negative  \\\n",
       "0  [far, worst, day, sinc, a, th, unhappi, cri, cri]   \n",
       "1  [splay, chaffman, long, time, realli, should, ...   \n",
       "2                                    [tell, unhappi]   \n",
       "3                                [a, alli, unconsci]   \n",
       "4                              [blast, a, love, you]   \n",
       "5                                 [year, a, unhappi]   \n",
       "\n",
       "                                             neutral  \n",
       "0  [decid, new, legisl, parti, leader, futur, cou...  \n",
       "1                         [b, brush, shake, as, tag]  \n",
       "2                                                [g]  \n",
       "3                  [an, oper, know, outskirt, amend]  \n",
       "4              [quaint, dig, budget, or, even, less]  \n",
       "5                                     [goffer, help]  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in tokenized_data_frame.columns:\n",
    "    corrected_stemmed_data[column] = tokenized_data_frame[column].apply(\n",
    "        lambda row: [stemmer.stem(get_closest_word(token)) for token in row])\n",
    "\n",
    "\n",
    "corrected_stemmed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Lemmatization with misspelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_lemmatizide_data = pd.DataFrame()\n",
    "\n",
    "for column in data_set.columns:\n",
    "    corrected_lemmatizide_data[column] = data_set[column].astype(str).apply(\n",
    "        lambda row: [token.lemma_ \n",
    "                     for token in nlp(\" \".join(get_closest_word(word) \n",
    "                                               for word in row.split()))]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[would, great, trick, happy]</td>\n",
       "      <td>[far, bad, day, since, a, th, unhappy, cry, cry]</td>\n",
       "      <td>[decide, new, legislative, party, leader, futu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[a, it, bring, a, angeleyes]</td>\n",
       "      <td>[splay, chaffman, long, time, really, should, ...</td>\n",
       "      <td>[b, brush, shake, as, tag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[adminicle, be, happy]</td>\n",
       "      <td>[tell, unhappy]</td>\n",
       "      <td>[g]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[thank, recent, follow, much, appreciate, happ...</td>\n",
       "      <td>[a, Allies, unconscious]</td>\n",
       "      <td>[an, operation, know, outskirt, amend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[definitely, looking, gave, try, anyway, happy]</td>\n",
       "      <td>[blast, a, love, you]</td>\n",
       "      <td>[quaint, dig, budget, or, even, less]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[happy]</td>\n",
       "      <td>[year, a, unhappy]</td>\n",
       "      <td>[goffer, help]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            positive  \\\n",
       "0                       [would, great, trick, happy]   \n",
       "1                       [a, it, bring, a, angeleyes]   \n",
       "2                             [adminicle, be, happy]   \n",
       "3  [thank, recent, follow, much, appreciate, happ...   \n",
       "4    [definitely, looking, gave, try, anyway, happy]   \n",
       "5                                            [happy]   \n",
       "\n",
       "                                            negative  \\\n",
       "0   [far, bad, day, since, a, th, unhappy, cry, cry]   \n",
       "1  [splay, chaffman, long, time, really, should, ...   \n",
       "2                                    [tell, unhappy]   \n",
       "3                           [a, Allies, unconscious]   \n",
       "4                              [blast, a, love, you]   \n",
       "5                                 [year, a, unhappy]   \n",
       "\n",
       "                                             neutral  \n",
       "0  [decide, new, legislative, party, leader, futu...  \n",
       "1                         [b, brush, shake, as, tag]  \n",
       "2                                                [g]  \n",
       "3             [an, operation, know, outskirt, amend]  \n",
       "4              [quaint, dig, budget, or, even, less]  \n",
       "5                                     [goffer, help]  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_lemmatizide_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Correct Slang words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
