{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              positive  \\\n",
      "0                            Surround positivity happy   \n",
      "1    Heres full art Glyph Keeper mummy token intere...   \n",
      "2              protect layer fat KISSES TheFashionIcon   \n",
      "3                                                  see   \n",
      "4                                      hype real happy   \n",
      "..                                                 ...   \n",
      "232                                      figures happy   \n",
      "233  Thats kaki tane amazing Foyound place Germany ...   \n",
      "234  Superstar thanks much kind words Look forward ...   \n",
      "235                                    Good luck happy   \n",
      "236                                        Thank happy   \n",
      "\n",
      "                                              negative  \\\n",
      "0    good morning nightmare im still wondering madd...   \n",
      "1    but use purple flowercrown display picture unh...   \n",
      "2                                      flavorful dream   \n",
      "3             tired theres nothing great combo unhappy   \n",
      "4                                           ha unhappy   \n",
      "..                                                 ...   \n",
      "232  Golly gosh simply dreadful havoc must wreaking...   \n",
      "233     Omg see drink alcohol Haha glad fun guys  Wish   \n",
      "234                                                      \n",
      "235                                       2010 Week 11   \n",
      "236  tak ambik wedding package cause poor unhappy a...   \n",
      "\n",
      "                                     neutral  \n",
      "0                    Hiring people task edge  \n",
      "1                    best colleges varsities  \n",
      "2                       electile dysfunction  \n",
      "3                   Rajes Stockhome syndrome  \n",
      "4                    Stephens tests autonomy  \n",
      "..                                       ...  \n",
      "232        3 shot dead protestors try rescue  \n",
      "233  nine injured CPRO North Central Railway  \n",
      "234                                6 injured  \n",
      "235                                  mandate  \n",
      "236                         venues audiences  \n",
      "\n",
      "[237 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "\n",
    "from lib.data_preparation import DataPreparation\n",
    "\n",
    "\n",
    "data_set = DataPreparation.remove_stopwords(DataPreparation.load_data())\n",
    "data_set = DataPreparation.remove_punctuation(data_set)\n",
    "\n",
    "\n",
    "data_set = data_set.sample(frac=0.2).reset_index(drop=True)\n",
    "print(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "tokenized_data_frame = pd.DataFrame()\n",
    "for column in data_set.columns:\n",
    "    tokenized_data_frame[column] = data_set[column].astype(str).apply(tokenizer.tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              positive  \\\n",
      "0                        [Surround, positivity, happy]   \n",
      "1    [Heres, full, art, Glyph, Keeper, mummy, token...   \n",
      "2        [protect, layer, fat, KISSES, TheFashionIcon]   \n",
      "3                                                [see]   \n",
      "4                                  [hype, real, happy]   \n",
      "..                                                 ...   \n",
      "232                                   [figures, happy]   \n",
      "233  [Thats, kaki, tane, amazing, Foyound, place, G...   \n",
      "234  [Superstar, thanks, much, kind, words, Look, f...   \n",
      "235                                [Good, luck, happy]   \n",
      "236                                     [Thank, happy]   \n",
      "\n",
      "                                              negative  \\\n",
      "0    [good, morning, nightmare, im, still, wonderin...   \n",
      "1    [but, use, purple, flowercrown, display, pictu...   \n",
      "2                                   [flavorful, dream]   \n",
      "3      [tired, theres, nothing, great, combo, unhappy]   \n",
      "4                                        [ha, unhappy]   \n",
      "..                                                 ...   \n",
      "232  [Golly, gosh, simply, dreadful, havoc, must, w...   \n",
      "233  [Omg, see, drink, alcohol, Haha, glad, fun, gu...   \n",
      "234                                                 []   \n",
      "235                                   [2010, Week, 11]   \n",
      "236  [tak, ambik, wedding, package, cause, poor, un...   \n",
      "\n",
      "                                            neutral  \n",
      "0                      [Hiring, people, task, edge]  \n",
      "1                       [best, colleges, varsities]  \n",
      "2                           [electile, dysfunction]  \n",
      "3                      [Rajes, Stockhome, syndrome]  \n",
      "4                       [Stephens, tests, autonomy]  \n",
      "..                                              ...  \n",
      "232        [3, shot, dead, protestors, try, rescue]  \n",
      "233  [nine, injured, CPRO, North, Central, Railway]  \n",
      "234                                    [6, injured]  \n",
      "235                                       [mandate]  \n",
      "236                             [venues, audiences]  \n",
      "\n",
      "[237 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Stemmming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              positive  \\\n",
      "0                             [surround, posit, happi]   \n",
      "1    [here, full, art, glyph, keeper, mummi, token,...   \n",
      "2          [protect, layer, fat, kiss, thefashionicon]   \n",
      "3                                                [see]   \n",
      "4                                  [hype, real, happi]   \n",
      "..                                                 ...   \n",
      "232                                     [figur, happi]   \n",
      "233  [that, kaki, tane, amaz, foyound, place, germa...   \n",
      "234  [superstar, thank, much, kind, word, look, for...   \n",
      "235                                [good, luck, happi]   \n",
      "236                                     [thank, happi]   \n",
      "\n",
      "                                              negative  \\\n",
      "0    [good, morn, nightmar, im, still, wonder, madd...   \n",
      "1    [but, use, purpl, flowercrown, display, pictur...   \n",
      "2                                      [flavor, dream]   \n",
      "3           [tire, there, noth, great, combo, unhappi]   \n",
      "4                                        [ha, unhappi]   \n",
      "..                                                 ...   \n",
      "232  [golli, gosh, simpli, dread, havoc, must, wrea...   \n",
      "233  [omg, see, drink, alcohol, haha, glad, fun, gu...   \n",
      "234                                                 []   \n",
      "235                                   [2010, week, 11]   \n",
      "236  [tak, ambik, wed, packag, caus, poor, unhappi,...   \n",
      "\n",
      "                                          neutral  \n",
      "0                        [hire, peopl, task, edg]  \n",
      "1                         [best, colleg, varsiti]  \n",
      "2                             [electil, dysfunct]  \n",
      "3                       [raje, stockhom, syndrom]  \n",
      "4                       [stephen, test, autonomi]  \n",
      "..                                            ...  \n",
      "232        [3, shot, dead, protestor, tri, rescu]  \n",
      "233  [nine, injur, cpro, north, central, railway]  \n",
      "234                                    [6, injur]  \n",
      "235                                      [mandat]  \n",
      "236                               [venu, audienc]  \n",
      "\n",
      "[237 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_data = pd.DataFrame()\n",
    "\n",
    "for column in tokenized_data_frame.columns:\n",
    "    stemmed_data[column] = tokenized_data_frame[column].apply(lambda row: [stemmer.stem(word) for word in row])\n",
    "print(stemmed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              positive  \\\n",
      "0                        [surround, positivity, happy]   \n",
      "1    [Heres, full, art, Glyph, Keeper, mummy, token...   \n",
      "2          [protect, layer, fat, kiss, thefashionicon]   \n",
      "3                                                [see]   \n",
      "4                                  [hype, real, happy]   \n",
      "..                                                 ...   \n",
      "232                                    [figure, happy]   \n",
      "233  [that, s, kaki, tane, amazing, Foyound, place,...   \n",
      "234  [Superstar, thank, much, kind, word, look, for...   \n",
      "235                                [good, luck, happy]   \n",
      "236                                     [thank, happy]   \n",
      "\n",
      "                                              negative  \\\n",
      "0    [good, morning, nightmare, I, m, still, wonder...   \n",
      "1    [but, use, purple, flowercrown, display, pictu...   \n",
      "2                                   [flavorful, dream]   \n",
      "3    [tired, there, s, nothing, great, combo, unhappy]   \n",
      "4                                        [ha, unhappy]   \n",
      "..                                                 ...   \n",
      "232  [golly, gosh, simply, dreadful, havoc, must, w...   \n",
      "233  [Omg, see, drink, alcohol, Haha, glad, fun, gu...   \n",
      "234                                                 []   \n",
      "235                                   [2010, week, 11]   \n",
      "236  [tak, ambik, wedding, package, cause, poor, un...   \n",
      "\n",
      "                                            neutral  \n",
      "0                        [hire, people, task, edge]  \n",
      "1                          [good, college, varsity]  \n",
      "2                           [electile, dysfunction]  \n",
      "3                      [Rajes, Stockhome, syndrome]  \n",
      "4                        [Stephens, test, autonomy]  \n",
      "..                                              ...  \n",
      "232        [3, shoot, dead, protestor, try, rescue]  \n",
      "233  [nine, injured, CPRO, North, Central, railway]  \n",
      "234                                     [6, injure]  \n",
      "235                                       [mandate]  \n",
      "236                               [venue, audience]  \n",
      "\n",
      "[237 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "lemmatized_words = pd.DataFrame()\n",
    "for column in data_set.columns:\n",
    "    lemmatized_words[column] = data_set[column].astype(str).apply(\n",
    "        lambda row: [token.lemma_ for token in nlp(row)]\n",
    "    )\n",
    "    \n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
