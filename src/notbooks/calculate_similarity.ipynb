{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "from scipy.sparse import csr_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "data_set = pd.read_csv(\"../data/raw_splits/train.csv\")\n",
    "tweet_vectors = pd.read_csv(\"../data/prepocessed_training_data/lemmatization_BinaryVectorizer.csv\")\n",
    "tweet_vectors.reset_index(drop=True, inplace=True)\n",
    "\n",
    "similarity_matrix = cosine_similarity(tweet_vectors)\n",
    "similarity_df = pd.DataFrame(similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12      324.446066\n",
       "1413    297.833668\n",
       "299     297.355814\n",
       "535     297.355814\n",
       "536     297.355814\n",
       "743     297.355814\n",
       "833     297.355814\n",
       "905     297.355814\n",
       "1055    297.355814\n",
       "1268    297.355814\n",
       "dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_set.iloc[3]['tweet'], data_set.iloc[1]['tweet'], similarity_df.iloc[3][1]\n",
    "\n",
    "\n",
    "\n",
    "for _, _, files in os.walk(\"../data/prepocessed_training_data\"):\n",
    "    for file in files:\n",
    "        print(f\"Top 10 similar tweets for preprocessing method{file[:-4]}\")\n",
    "        data_set = pd.read_csv(f\"../data/raw_splits/{file}\")\n",
    "        similarities = []\n",
    "        for i in range(len(similarity_df)):\n",
    "            for j in range(i+1, len(similarity_df)):\n",
    "                similarities.append((i, j, similarity_df.iloc[i][j]))\n",
    "        similarity_pairs = pd.DataFrame(similarities, columns=[\"tweet_1\", \"tweet_2\", \"similarity\"])\n",
    "        \n",
    "        tweet_similarity_scores = similarity_df.sum(axis=1) - 1  \n",
    "        \n",
    "        top_10_similar_tweets = tweet_similarity_scores.nlargest(10)\n",
    "\n",
    "        top_10_similar_tweets\n",
    "\n",
    "        for i in range(10):\n",
    "            tweet_index = top_10_similar_tweets.index[i]\n",
    "            similarity = top_10_similar_tweets.iloc[i]\n",
    "            print(f\"Tweet index: {tweet_index}\")\n",
    "        print(\"*\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
