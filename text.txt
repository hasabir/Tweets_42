project_root/
│
├── data/
│   ├── raw/                            # Original datasets (processedPositive.csv, processedNegative.csv, processedNeutral.csv)
│   ├── cleaned/                        # Preprocessed datasets
│   └── vectors/                        # Vectorized data (e.g., binary, word counts, TF-IDF vectors)
│
├── notebooks/
│   ├── data_cleaning.ipynb             # Notebook for data cleaning and preprocessing (tokenization, stemming, etc.)
│   ├── vectorization.ipynb             # Notebook for vectorizing tweets (binary, word counts, TF-IDF)
│   └── analysis.ipynb                  # Notebook for analyzing vectorized data and training models
│
├── models/                             # Directory to save trained machine learning models
│   ├── binary_presence_model.pkl
│   ├── word_count_model.pkl
│   └── tfidf_model.pkl
│
├── src/                                # Python scripts
│   ├── preprocessing.py                # Script for text preprocessing functions
│   ├── vectorization.py                # Script for vectorization methods
│   └── model_training.py               # Script for training and evaluating models
│
├── results/
│   ├── evaluation_metrics/             # Metrics (accuracy, F1-score, etc.) for each approach
│   └── visualizations/                 # Any charts, graphs, or visual results
│
├── reports/
│   ├── documentation.md                # Main project documentation
│   └── findings_summary.md             # Summary of findings and results
│
└── requirements.txt                    # List of dependencies (e.g., pandas, scikit-learn, nltk)
